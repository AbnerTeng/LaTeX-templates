\documentclass[12pt]{article}
\linespread{2.0}
\usepackage{geometry}
\geometry{head=10mm,foot=10mm,left=20mm,right=20mm}

\usepackage{amsmath,amsthm,amssymb,scrextend}
\usepackage{fancyhdr}
\setlength{\headheight}{14.5pt}
\addtolength{\topmargin}{-2.5pt}
\pagestyle{fancy}

\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\lstset{
			backgroundcolor=\color{red!50!green!50!blue!50!white!20},
			breaklines = true,
			tabsize=2,
			commentstyle=\color{codegreen},
			keywordstyle=\color{magenta},
			numberstyle=\tiny\color{codegray},
			stringstyle=\color{codepurple},
	    }

\usepackage{graphicx}
\usepackage{float}
\usepackage{multicol}
\usepackage[colorlinks=true, pdfstartview=FitV, linkcolor=blue,
citecolor=blue, urlcolor=blue]{hyperref}

\begin{document}

\chead{Statistic Cheat Sheet}
\section*{CH4. Multi-Variable Distribution}
\subsection*{Conditional pdf}
Given $X, Y$'s joint pdf is $f_{XY}(xy)$
\begin{equation}
    f(x|y)=\frac{f(x,y)}{f(y)}
\end{equation}
\begin{equation}
    f(y|x)=\frac{f(x,y)}{f(x)}
\end{equation}
Use $f(y|x)$ as examples:
\begin{enumerate}
    \item for $x$, we don't need to concern the function relationship between $x$ and $y$
    \item for $y$, we need to concern the function relationship between $x$ and $y$
\end{enumerate}
If the condition is a point:
\begin{equation}
    P(X<a|Y=y)=\int_{-\infty}^a f(x|y)dx=\int_{-\infty}^a \frac{f(x,y)}{f(y)}dx
\end{equation}
If the condition is a range:
\begin{equation}
    P(X<a|Y<b)=\frac{P(X<a \cap Y<b)}{P(Y<b)}
\end{equation}
\subsection*{Moments}
Given $X$ and $Y$ are bivariate random variables, their joint pdf is $f(x,y)$, then the expected value of $g(x,y)$ is:
\newline
\begin{equation}
    E[g(X,Y)]=\int_y\int_x g(x,y)f(x,y)dxdy = \int_x\int_y g(x,y)f(x,y)dydx
\end{equation}
\newline
\newline
Covariance and correlation coefficient
\newline
\begin{equation}
    \sigma_{XY}=Cov(X,Y)=E\{[X-E(X)][Y-E(Y)]\}=E(XY)-E(X)E(Y)
\end{equation}
\begin{equation}
    \rho_{XY}=Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)}\sqrt{Var(Y)}}=\frac{\sigma_{XY}}{\sigma_X \sigma_Y}
\end{equation}
\newpage
Properties:
\begin{enumerate}
    \item $E(aX+bY)=E(aX)+E(bY)=aE(x)+bE(y)$
    \item $Cov(X,X)=Var(X)$
    \item $Cov(X,c)=0$
    \item $Var(aX+bY)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y)$
    \item $Cov(aX+b,cY+d)=acCov(X,Y)$
    \item $Corr(aX+b,cY+d)=\frac{ac}{|ac|}Corr(X,Y)=sign(ac)Corr(X,Y)$
\end{enumerate}
Given $X_1,X_2,\ldots, X_n$, then:
\begin{equation}
    E(\sum_{i=1}^n X_i)=\sum_{i=1}^n E(X_i)
\end{equation}
\begin{equation}
    Var(\sum_{i=1}^n X_i)=\sum_{i=1}^n Var(X_i)+\sum_{i=1}^n\sum_{j\neq i}Cov(X_i,X_j)
\end{equation}
\begin{equation}
    E(\sum_{i=1}^n a_i X_i)=\sum_{i=1}^n a_i E(X_i)
\end{equation}
\begin{equation}
    Var(\sum_{i=1}^n a_i X_i)=\sum_{i=1}^n a_i^2 Var(X_i)+\sum_{i=1}^n \sum_{j \neq i}a_i a_j Cov(X_i, X_j)
\end{equation}
Properties of individual r.v.
\begin{description}
    \item[1.] $E[g(X)h(Y)]=E[g(X)]E[h(Y)]$
    \item[2.] $Var(X+Y)=Var(X-Y)=Var(X)+Var(Y)$
    \item[3.] Let $Z=X+Y,\ M_Z(t)=E[e^{t(X+Y)}]=M_X(t)+M_Y(t)$
    \item[Given $X_1, X_2, \ldots , X_n$ are mutually independent]
    \item[4.] Let $Y=\sum_{i=1}^n X_i, M_Y(t)=\prod_{i=1}^n M_{X_i}(t)$
\end{description}
\textbf{$i.i.d$ random variables}
\newline
If a sequence of rnadom variables ${X_1,X_2,\ldots X_n}$ are mutually independent and identically distributed, they're called $i.i.d$ random variables.
\begin{enumerate}
    \item $E(X_i)=\mu$
    \item $Var(X_i)=\sigma^2$
    \item $M_{X_i}(t)=M_X(t)$
\end{enumerate}
Let $Y=\sum_{i=1}^n X_i$
\begin{enumerate}
    \item $E(Y)=n\mu$
    \item $Var(Y)=n\sigma^2$
    \item $M_Y(t)=[M_X(t)]^n$
\end{enumerate}
Let $\bar X=\frac{\sum_{i=1}^n X_i}{n}=\frac{Y}{n}$
\begin{enumerate}
    \item $E(\bar X)=\mu$
    \item $Var(\bar X)=\frac{\sigma^2}{n}$
    \item $M_{\bar X}(t)=[M_X(\frac{t}{n})]^n$
\end{enumerate}
\subsection*{Conditional Expectation and variance}
\textbf{conditional expectation}
\newline
Given $X=x$, $Y$'s conditional expectation is
\begin{equation}
    E(Y|X=x)=\mu_{Y|X=x}=\int_y yf(y|x)dy
\end{equation}
Given $Y=y$, $X$'s conditional expectation is
\begin{equation}
    E(X|Y=y)=\mu_{X|Y=y}=\int_x xf(x|y)dx
\end{equation}
\textbf{conditional variance}
\newline
Given $X=x$, $Y$'s conditional variance is
\begin{equation}
    \begin{aligned}
        \sigma^2_{Y|X=x}&=Var(Y|X=x)=E\{[Y-E(Y|X=x)]^2|X=x\}\\&=\int_y[y-E(Y|X=x)]^2f(y|x)dy
    \end{aligned}
\end{equation}
Given $Y=y$, $X$'s conditional variance is
\begin{equation}
    \begin{aligned}
        \sigma^2_{X|Y=y}&=Var(X|Y=y)=E\{[X-E(X|Y=y)]^2|Y=y\}\\&=\int_x[x-E(X|Y=y)]^2f(x|y)dx
    \end{aligned}
\end{equation}
\textbf{useful rule}
\begin{equation}
    E[h(X)|X]=h(X)
\end{equation}
\begin{equation}
    E[h(X)g(Y)|X]=h(X)E[g(Y)|X]
\end{equation}
\textbf{Simple law of iterated expectations, LIE}
\begin{equation}
    E[E(Y|X)]=E(Y)
\end{equation}
<proof>
    \[E(Y|X=x)=\int_y yf(y|x)dy\]
According to useful rule:
    \[E[h(X)]=\int_x h(x)f(x)dx\]
\begin{equation*}
    \begin{aligned}
        E[E(Y|X)] &=\int_x E(Y|X=x)f(x)dx = \int_x \int_y yf(y|x)dyf(x)dx \\
        &= \int_x\int_y y\frac{f(x,y)}{f(x)}dyf(x)dx = \int_x \int_y yf(x,y)dydx \\
        &= \int_y y\Big(\int_x f(x,y)dx\Big)dy = \int_y yf(y)dy = E(Y)
    \end{aligned}
\end{equation*}
\textbf{Generalized LIE}
\begin{equation}
    E[g(Y)]=E\{E[g(Y)|X]\}
\end{equation}
\subsection*{jacobian's transformation method}
\begin{description}
    \item[Step 1.] From $w,z$ get $x,y$
    \item[Step 2.] 
        jacobian term:
        \begin{equation*}
            \begin{Vmatrix}
                \frac{\partial h_1(w,z)}{\partial w} & \frac{\partial h_1(w,z)}{\partial z} \\
                \frac{\partial h_2(w,z)}{\partial w} & \frac{\partial h_2(w,z)}{\partial z}
            \end{Vmatrix}
        \end{equation*}
    \item[Step 3.] Key point: find the range of $w$ and $z$
    \item[Step 4.] Bring in: $f_{WZ}(w,z) = f_{XY}[x = h_1(w,z), y = h_2(w,z)]\times |J|$   
\end{description}
\end{document}